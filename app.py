import os
import pandas as pd
import pickle
import numpy as np
import streamlit as st
import plotly.express as px
from streamlit_option_menu import option_menu
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LogisticRegression
import base64
from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, LabelEncoder



st.set_page_config(page_title="Health Assistant",
                   layout="wide",
                   page_icon="üßë‚Äç‚öïÔ∏è")



working_dir = os.path.dirname(os.path.abspath(__file__))

heart_disease_model = pickle.load(open(f'{working_dir}/saved_models/heart_disease_model.sav', 'rb'))

with st.sidebar:
    selected = option_menu('Menu',
                           ['Upload CSV',
                            'Heart Disease Prediction',
                            'Data Analysis'],
                           menu_icon='hospital-fill',
                           icons=['cloud-upload', 'heart','data'],
                           default_index=0)


#----------------------------------------------------------------------------------------------------------    

if selected == 'Upload CSV':
    
    st.title('Upload CSV')

    # uploaded_files = st.file_uploader("Choose a CSV file", accept_multiple_files=True)
    
    # if uploaded_files:
    #     for uploaded_file in uploaded_files:
    #         df = pd.read_csv(uploaded_file)
    #         st.write(uploaded_file.name)
    #         st.write(df.head(1))
    #         col1, col2 = st.columns(2)
        
        #  def predict_single_variable(user_input1):
        #     X = df[user_input1[0]].values.reshape(-1, 1)  # Bi·∫øn ƒë·ªôc l·∫≠p
        #     y = df[user_input1[1]].values  # Bi·∫øn ph·ª• thu·ªôc

        #     model = LinearRegression()
        #     model.fit(X, y)

        #     diab_diagnosis1 = model.predict(X)

        #     return diab_diagnosis1
        
        # def predict_knn_single_variable(user_input1):
            # X = df[user_input1[0]].values.reshape(-1, 1)  # Bi·∫øn ƒë·ªôc l·∫≠p
            # y = df[user_input1[1]].values  # Bi·∫øn ph·ª• thu·ªôc

            # model = KNeighborsRegressor(n_neighbors=5)
            # model.fit(X, y)

            # diab_diagnosis = model.predict(X)

            # return diab_diagnosis
        
        # def predict_logistic_single_variable(user_input1):
            # X = df[user_input1[0]].values.reshape(-1, 1)  # Bi·∫øn ƒë·ªôc l·∫≠p
            # y = df[user_input1[1]].values  # Bi·∫øn ph·ª• thu·ªôc

            # model = LogisticRegression()
            # model.fit(X, y)

            # diab_diagnosis = model.predict(X)
        
            # return diab_diagnosis
        
        
 
        
    #     with col1:
    #         st.write("ƒê∆°n bi·∫øn")
    #         Independent1 = st.selectbox("Bi·∫øn ƒë·ªôc l·∫≠p", (df.columns),index=None,placeholder="H√£y ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p")
    
    #     with col1:    
    #         Dependent1 = st.selectbox("Bi·∫øn ph·ª• thu·ªôc", (df.columns),index=None,placeholder="H√£y ch·ªçn bi·∫øn ph·ª• thu·ªôc")
       
    #     with col1:    
    #         MH = st.selectbox("M√¥ h√¨nh",("Linear Regression", "KNN", "Logistics regression"),index=None,placeholder="H√£y ch·ªçn m√¥ h√¨nh")


            # if MH == "Linear Regression":
                # if st.button('K·∫øt qu·∫£ ƒë∆°n bi·∫øn'): 
                #     user_input1 = [Independent1, Dependent1]
                #     diab_diagnosis1 = predict_single_variable(user_input1) 

                #     plt.figure(figsize=(10, 6))
                #     plt.scatter(df[user_input1[0]], df[user_input1[1]], color='blue', label='Actual data')
                #     plt.plot(df[user_input1[0]], diab_diagnosis1, color='red', label='Predicted data')
                #     plt.xlabel(user_input1[0])
                #     plt.ylabel(user_input1[1])
                #     plt.title('Linear Regression')
                #     plt.legend()
                #     plt.grid(True)
                #     st.pyplot(plt)
                    
            # if MH == "KNN":
                # if st.button('K·∫øt qu·∫£ ƒë∆°n bi·∫øn'): 
                #     user_input1 = [Independent1, Dependent1]
                #     diab_diagnosis1 = predict_knn_single_variable(user_input1) 

                #     plt.figure(figsize=(10, 6))
                #     plt.scatter(df[user_input1[0]], df[user_input1[1]], color='blue', label='Actual data')
                #     plt.plot(df[user_input1[0]], diab_diagnosis1, color='red', label='Predicted data')
                #     plt.xlabel(user_input1[0])
                #     plt.ylabel(user_input1[1])
                #     plt.title('KNN Regression')
                #     plt.legend()
                #     plt.grid(True)
                #     st.pyplot(plt)
                    
            # if MH == "Logistics regression":
                # if st.button('K·∫øt qu·∫£ ƒë∆°n bi·∫øn'): 
                #     user_input1 = [Independent1, Dependent1]
                #     diab_diagnosis1 = predict_logistic_single_variable(user_input1) 

                #     plt.figure(figsize=(10, 6))
                #     plt.scatter(df[user_input1[0]], df[user_input1[1]], color='blue', label='Actual data')
                #     plt.plot(df[user_input1[0]],  diab_diagnosis1, color='red', label='Logistic Regression')
                #     plt.xlabel(user_input1[0])
                #     plt.ylabel(user_input1[1])
                #     plt.title('Logistic Regression')
                #     plt.legend()
                #     plt.grid(True)
                #     st.pyplot(plt)
                

    #     def predict_multi_variable(user_input2):
    #         # L·∫•y d·ªØ li·ªáu t·ª´ file CSV ƒë√£ t·∫£i l√™n
    #         X = df[[user_input2[0], user_input2[1]]].values  # Bi·∫øn ƒë·ªôc l·∫≠p
    #         y = df[user_input2[2]].values  # Bi·∫øn ph·ª• thu·ªôc
            
    #         model = LinearRegression()
    #         model.fit(X, y)

    #         diab_diagnosis2 = model.predict(X)

    #         # V·∫Ω ƒë∆∞·ªùng h·ªìi quy
    #         x_min, x_max = X[:, 0].min(), X[:, 0].max()
    #         y_min, y_max = X[:, 1].min(), X[:, 1].max()
    #         xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    #         Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    #         Z = Z.reshape(xx.shape)

    #         return diab_diagnosis2, xx, yy, Z
        
    #     def predict_knn_multi_variable(user_input2):
    #         X = df[[user_input2[0], user_input2[1]]].values  # Bi·∫øn ƒë·ªôc l·∫≠p
    #         y = df[user_input2[2]].values  # Bi·∫øn ph·ª• thu·ªôc
            
    #         model = KNeighborsRegressor(n_neighbors=5)
    #         model.fit(X, y)

    #         diab_diagnosis2 = model.predict(X)

    #         x_min, x_max = X[:, 0].min(), X[:, 0].max()
    #         y_min, y_max = X[:, 1].min(), X[:, 1].max()
    #         xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    #         Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    #         Z = Z.reshape(xx.shape)

    #         return diab_diagnosis2, xx, yy, Z
        
    #     def predict_logistic_multi_variable(user_input2):
    #         X = df[[user_input2[0], user_input2[1]]].values  # Bi·∫øn ƒë·ªôc l·∫≠p
    #         y = df[user_input2[2]].values  # Bi·∫øn ph·ª• thu·ªôc
            
    #         model = LogisticRegression()
    #         model.fit(X, y)

    #         diab_diagnosis2 = model.predict(X)

    #         x_min, x_max = X[:, 0].min(), X[:, 0].max()
    #         y_min, y_max = X[:, 1].min(), X[:, 1].max()
    #         xx, yy = np.meshgrid(np.linspace(x_min, x_max, 100), np.linspace(y_min, y_max, 100))
    #         Z = model.predict(np.c_[xx.ravel(), yy.ravel()])
    #         Z = Z.reshape(xx.shape)

    #         return diab_diagnosis2, xx, yy, Z

    #     with col2:
    #         st.write("ƒêa bi·∫øn")
    #         Independent2 = st.selectbox("Bi·∫øn ƒë·ªôc l·∫≠p ", (df.columns),index=None,placeholder="H√£y ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p ")
            
    #     with col2:
    #         Independent3 = st.selectbox("Bi·∫øn ƒë·ªôc l·∫≠p ", (df.columns),index=None,placeholder="H√£y ch·ªçn bi·∫øn ƒë·ªôc l·∫≠p")
            
    #     with col2:
    #         Dependent2 = st.selectbox("Bi·∫øn ph·ª• thu·ªôc ", (df.columns),index=None,placeholder="H√£y ch·ªçn bi·∫øn ph·ª• thu·ªôc ")
            
    #     with col2:
            # MH1 = st.selectbox("M√¥ h√¨nh",("Linear Regression ", "KNN ", "Logistics regression "),index=None,placeholder="H√£y ch·ªçn m√¥ h√¨nh")

            # if MH1 == "Linear Regression ":
            #     if st.button('K·∫øt qu·∫£ ƒëa bi·∫øn'):
            #         user_input2 = [Independent2, Independent3, Dependent2]
            #         diab_diagnosis2, xx, yy, Z = predict_multi_variable(user_input2) 

            #         fig = plt.figure(figsize=(10, 6))
            #         ax = fig.add_subplot(111, projection='3d')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], df[user_input2[2]], color='blue', label='Actual data')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], diab_diagnosis2, color='red', label='Predicted data')
            #         ax.plot_surface(xx, yy, Z, alpha=0.5, cmap='viridis', label='Regression Plane')
            #         ax.set_xlabel(user_input2[0])
            #         ax.set_ylabel(user_input2[1])
            #         ax.set_zlabel(user_input2[2])
            #         ax.set_title('Linear Regression')
            #         ax.legend()
            #         st.pyplot(fig)
                    
            # if MH1 == "KNN ":
            #     if st.button('K·∫øt qu·∫£ ƒëa bi·∫øn'):
            #         user_input2 = [Independent2, Independent3, Dependent2]
            #         diab_diagnosis2, xx, yy, Z = predict_knn_multi_variable(user_input2) 

            #         fig = plt.figure(figsize=(10, 6))
            #         ax = fig.add_subplot(111, projection='3d')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], df[user_input2[2]], color='blue', label='Actual data')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], diab_diagnosis2, color='red', label='Predicted data')
            #         ax.plot_surface(xx, yy, Z, alpha=0.5, cmap='viridis', label='Regression Plane')
            #         ax.set_xlabel(user_input2[0])
            #         ax.set_ylabel(user_input2[1])
            #         ax.set_zlabel(user_input2[2])
            #         ax.set_title('KNN Regression')
            #         ax.legend()
            #         st.pyplot(fig)
                    
            # if MH1 == "Logistics regression ":
            #     if st.button('K·∫øt qu·∫£ ƒëa bi·∫øn'):
            #         user_input2 = [Independent2, Independent3, Dependent2]
            #         diab_diagnosis2, xx, yy, Z = predict_logistic_multi_variable(user_input2) 

            #         fig = plt.figure(figsize=(10, 6))
            #         ax = fig.add_subplot(111, projection='3d')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], df[user_input2[2]], color='blue', label='Actual data')
            #         ax.scatter(df[user_input2[0]], df[user_input2[1]], diab_diagnosis2, color='red', label='Predicted data')
            #         ax.plot_surface(xx, yy, Z, alpha=0.5, cmap='viridis', label='Regression Plane')
            #         ax.set_xlabel(user_input2[0])
            #         ax.set_ylabel(user_input2[1])
            #         ax.set_zlabel(user_input2[2])
            #         ax.set_title('Linear Regression')
            #         ax.legend()
            #         st.pyplot(fig)
    
#----------------------------------------------------------------------------------------------------------    

if selected == 'Heart Disease Prediction':

    # page title#
    st.title('Heart Disease Prediction using ML')

#     col1, col2, col3 = st.columns(3)

#     with col1:
#         age = st.text_input('Tu·ªïi')

#     with col2:
#         sex = st.text_input('Gi·ªõi t√≠nh (1 = Nam, 0 = N·ªØ)')

#     with col3:
#         cp = st.text_input('Lo·∫°i ƒëau ng·ª±c')

#     with col1:
#         trestbps = st.text_input('Huy·∫øt √°p l√∫c ngh·ªâ (t√≠nh b·∫±ng mm Hg)')

#     with col2:
#         chol = st.text_input('Cholestoral mg/dl')

#     with col3:
#         fbs = st.text_input('ƒê∆∞·ªùng trong m√°u > 120 mg/dl (1 = true; 0 = false)')

#     with col1:
#         restecg = st.text_input('K·∫øt qu·∫£ ƒëi·ªán t√¢m ƒë·ªì l√∫c ngh·ªâ ng∆°i')

#     with col2:
#         thalach = st.text_input('Nh·ªãp tim t·ªëi ƒëa ƒë·∫°t ƒë∆∞·ª£c')

#     with col3:
#         exang = st.text_input('T·∫≠p th·ªÉ d·ª•c c√≥ g√¢y ƒëau t·∫Øc ng·ª±c kh√¥ng (1 = C√≥; 0 = Kh√¥ng)')

#     with col1:
#         oldpeak = st.text_input('Ch√™nh l·ªách ƒëoan ST trong khi t·∫≠p th·ªÉ d·ª•c so v·ªõi l√∫c ngh·ªâ')

#     with col2:
#         slope = st.text_input('ƒê·ªô d·ªëc t·∫°i ƒë·ªânh c·ªßa ƒëo·∫°n ST khi t·∫≠p th·ªÉ d·ª•c')

#     with col3:
#         ca = st.text_input('S·ªë l∆∞·ª£ng ƒëo·∫°n m·∫°ch ch√≠nh')

#     with col1:
#         thal = st.text_input('1 = b√¨nh th∆∞·ªùng, 2 = l·ªói c·ªë ƒë·ªãnh, 3 = khi·∫øm khuy·∫øt c√≥ th·ªÉ ƒë·∫£o ng∆∞·ª£c')

#     # code for Prediction
#     heart_diagnosis = ''

#     # creating a button for Prediction

#     if st.button('D·ª± ƒëo√°n b·ªánh tim'):

#         user_input = [age, sex, cp, trestbps, chol, fbs, restecg, thalach, exang, oldpeak, slope, ca, thal]

#         user_input = [float(x) for x in user_input]

#         heart_prediction = heart_disease_model.predict([user_input])

#         if heart_prediction[0] == 1:
#             heart_diagnosis = 'Ng∆∞·ªùi n√†y c√≥ m·∫Øc b·ªánh tim'
#         else:
#             heart_diagnosis = 'Ng∆∞·ªùi n√†y kh√¥ng m·∫Øc b·ªánh tim'

#     st.success(heart_diagnosis)

#----------------------------------------------------------------------------------------------------------    

if selected == 'Data Analysis':
    
    st.title('Clean Data')

    
    uploaded_files = st.file_uploader("Choose a CSV file", accept_multiple_files=True)
    

    if uploaded_files:
        
        for uploaded_file in uploaded_files:
            df = pd.read_csv(uploaded_file)
            st.write(uploaded_file.name)
            st.write("Hi·ªÉn th·ªã 5 h√†ng ƒë·∫ßu ti√™n c·ªßa dataset")
            st.write(df.head(5))
            st.write("S·ªë h√†ng v√† s·ªë c·ªôt trong dataset")
            st.write(df.shape)
            st.write("Ki·ªÉu d·ªØ li·ªáu c·ªßa c√°c c·ªôt trong dataset")
            st.write(df.dtypes)
            st.write("Ki·ªÉm tra missing values")
            st.write(df.isnull().sum())
            st.write("M√¥ t·∫£ d·ªØ li·ªáu")
            st.write(df.describe())
           
            
            
            
            # H√†m x√≥a c·ªôt
            def remove_col(my_df, unwanted_col):
                my_df = my_df.drop(columns=unwanted_col, errors='ignore')
                return my_df
            
            # H√†m ƒëi·ªÅn gi√° tr·ªã null
            def fill_null_values(my_df, selected_columns):
                for col in selected_columns:
                    if my_df[col].dtype == "object":
                        mode_val = my_df[col].mode()[0]
                        my_df[col].fillna(mode_val, inplace=True)
                    if my_df[col].dtype == "int64" or my_df[col].dtype == "float64":  # N·∫øu c·ªôt l√† s·ªë
                        unique_values = my_df[col].dropna().unique()
                        if len(unique_values) == 2 and set(unique_values) == {0, 1}:  # N·∫øu ch·ªâ c√≥ 2 gi√° tr·ªã v√† l√† 0 ho·∫∑c 1
                            mode_val = my_df[col].mode()[0]  # L·∫•y mode (gi√° tr·ªã xu·∫•t hi·ªán nhi·ªÅu nh·∫•t)
                            my_df[col].fillna(mode_val, inplace=True)
                    if my_df[col].dtype == "int64" or my_df[col].dtype == "int32":  # N·∫øu c·ªôt l√† s·ªë nguy√™n
                        if my_df[col].nunique() > 2:  # N·∫øu c√≥ nhi·ªÅu h∆°n 2 gi√° tr·ªã kh√°c nhau
                            mean_val = my_df[col].mean().astype(int)  # L·∫•y gi√° tr·ªã trung b√¨nh ki·ªÉu int
                            # Thay th·∫ø c√°c gi√° tr·ªã 0 b·∫±ng gi√° tr·ªã trung b√¨nh
                            my_df[col] = my_df[col].replace(0, mean_val)
                            my_df[col].fillna(mean_val, inplace=True)  # ƒêi·ªÅn gi√° tr·ªã null b·∫±ng gi√° tr·ªã trung b√¨nh
                    if my_df[col].dtype == "float64" or my_df[col].dtype == "float32":  # N·∫øu c·ªôt l√† s·ªë th·ª±c
                        if my_df[col].nunique() > 2:  # N·∫øu c√≥ nhi·ªÅu h∆°n 2 gi√° tr·ªã kh√°c nhau
                            mean_val = my_df[col].mean().astype(float)  # L·∫•y gi√° tr·ªã trung b√¨nh ki·ªÉu float
                            # Thay th·∫ø c√°c gi√° tr·ªã 0 b·∫±ng gi√° tr·ªã trung b√¨nh
                            my_df[col] = my_df[col].replace(0, mean_val)
                            my_df[col].fillna(mean_val, inplace=True)  # ƒêi·ªÅn gi√° tr·ªã null b·∫±ng gi√° tr·ªã trung b√¨nh
                return my_df
            
            # H√†m √©p ki·ªÉu
            def convert_column_dtype(my_df, column, new_dtype):
                try:
                    if new_dtype == "int32":
                        # Fill NaN and inf with a placeholder value (here we use -1)
                        my_df[column].fillna(0, inplace=True)
                        my_df[column].replace([np.inf, -np.inf], 0, inplace=True)
                        my_df[column] = my_df[column].astype(np.float32).astype(np.int32)
                    elif new_dtype == "int64":
                        my_df[column].fillna(0, inplace=True)
                        my_df[column].replace([np.inf, -np.inf], 0, inplace=True)
                        my_df[column] = my_df[column].astype(np.float64).astype(np.int64)
                    elif new_dtype == "float32":
                        my_df[column].replace([np.inf, -np.inf], np.nan, inplace=True)
                        my_df[column] = my_df[column].astype(np.float32)
                    elif new_dtype == "float64":
                        my_df[column].replace([np.inf, -np.inf], np.nan, inplace=True)
                        my_df[column] = my_df[column].astype(np.float64)
                    elif new_dtype == "object":
                        my_df[column] = my_df[column].astype(str)
                except Exception as e:
                    st.error(f"Error converting column {column} to {new_dtype}: {e}")
                return my_df
            
            # H√†m check outliers
            def check_outliers_plot(my_df, selected_column):
                # T√≠nh gi√° tr·ªã Q1, Q3 v√† IQR
                Q1 = my_df[selected_column].quantile(0.25)
                Q3 = my_df[selected_column].quantile(0.75)
                IQR = Q3 - Q1
                
                # T√¨m gi√° tr·ªã ngo·∫°i l·ªá d∆∞·ªõi v√† tr√™n
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # T·∫°o DataFrame ch·ª©a th√¥ng tin v·ªÅ outlier
                outliers = my_df[(my_df[selected_column] < lower_bound) | (my_df[selected_column] > upper_bound)]
                
                if outliers.empty:
                    st.write("No outliers found.")
                else:
                    # V·∫Ω bi·ªÉu ƒë·ªì box plot
                    fig = px.box(my_df, y=selected_column, title=f'Box plot of {selected_column}')
                    st.plotly_chart(fig)
                    
            def remove_outliers(my_df, selected_column):
                # T√≠nh gi√° tr·ªã Q1, Q3 v√† IQR
                Q1 = my_df[selected_column].quantile(0.25)
                Q3 = my_df[selected_column].quantile(0.75)
                IQR = Q3 - Q1
                
                # T√¨m gi√° tr·ªã ngo·∫°i l·ªá d∆∞·ªõi v√† tr√™n
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                # Lo·∫°i b·ªè c√°c ngo·∫°i l·ªá kh·ªèi d·ªØ li·ªáu
                my_df = my_df[(my_df[selected_column] >= lower_bound) & (my_df[selected_column] <= upper_bound)]
                
                return my_df
                        
            # H√†m l∆∞u dataset
            def save_dataset(my_df, filename):
                my_df.to_csv(filename, index=False)
                st.success(f"Dataset saved as {filename}")
            
            # H√†m download dataset
            def get_download_link(my_df, filename, text):
                csv = my_df.to_csv(index=False)
                b64 = base64.b64encode(csv.encode()).decode()  # Encode to base64
                href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
                return href

            # H√†m x·ª≠ l√Ω duplicate
            def handle_duplicates(my_df, subset_columns):
                # T√¨m c√°c h√†ng tr√πng l·∫∑p
                duplicates = my_df[my_df.duplicated(subset=subset_columns, keep=False)]
                st.write("Duplicates found before handling:")
                st.write(duplicates)
                            
                if duplicates.empty:
                    st.write("No duplicates found.")
                    return my_df, False  # Kh√¥ng c√≥ duplicate
                else:
                    # X√≥a c√°c h√†ng tr√πng l·∫∑p
                    my_df = my_df.drop_duplicates(subset=subset_columns, keep='first')
                    st.write("Duplicates handled successfully.")
                    return my_df, True  # ƒê√£ x·ª≠ l√Ω duplicate
           
            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p One-Hot Encoding
            def one_hot_encode(my_df, column):
                encoder = OneHotEncoder()
                encoded = encoder.fit_transform(my_df[[column]]).toarray()
                df_encoded = pd.DataFrame(encoded, columns=encoder.get_feature_names_out([column]))
                my_df = pd.concat([my_df, df_encoded], axis=1)
                my_df.drop(columns=[column], inplace=True)
                return my_df

            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p Ordinal Encoding
            def ordinal_encode(my_df, column):
                encoder = OrdinalEncoder()
                my_df[[column]] = encoder.fit_transform(my_df[[column]])
                return my_df

            # H√†m m√£ h√≥a bi·∫øn ph√¢n lo·∫°i b·∫±ng ph∆∞∆°ng ph√°p Label Encoding
            def label_encode(my_df, column):
                encoder = LabelEncoder()
                my_df[column] = encoder.fit_transform(my_df[column])
                return my_df               
            

            


                        
            # Ki·ªÉm tra n·∫øu session state ch∆∞a t·ªìn t·∫°i, kh·ªüi t·∫°o m·ªõi
            if 'my_df' not in st.session_state:
                st.session_state.my_df = pd.DataFrame()
                st.session_state.my_df = df.copy()
            if 'deleted_columns' not in st.session_state:
                st.session_state.deleted_columns = []    
            
            tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(["Remove Columns", 
                                                                      "Fill Null Values", 
                                                                      "Handle duplicates", 
                                                                      "Remove Rows with Null", 
                                                                      "Change Data Types", 
                                                                      "Check Outliers", 
                                                                      "Encode Categorical Variables", 
                                                                      "Save dataset"])
        
            with tab1:
                st.write("Remove Columns")
                unwanted_col = st.multiselect("Remove column", st.session_state.my_df.columns, key="deleted_columns")
                if st.button('Remove'):
                    st.session_state.my_df = remove_col(st.session_state.my_df, unwanted_col)
                    st.session_state.deleted_columns.extend(unwanted_col)
                    st.write(st.session_state.my_df.head(5))

            with tab2:
                st.header("Fill Null Values")
                st.write(st.session_state.my_df.head(5))
                st.write("Choose columns to fill null values")
                selected_columns = st.multiselect("Columns", st.session_state.my_df.columns, key="fill_null_values")
                if st.button('Fill Null Values'):
                    # √Åp d·ª•ng h√†m fill_null_values cho c√°c c·ªôt ƒë√£ ch·ªçn
                    filled_df = fill_null_values(st.session_state.my_df, selected_columns)
                    # C·∫≠p nh·∫≠t l·∫°i DataFrame
                    st.session_state.my_df = filled_df
                    st.write("Null values filled for selected columns")
                    st.write(st.session_state.my_df.head(5))

            
            with tab3:
                st.header("Handle Duplicates")
                            
                # T·∫°o bi·∫øn tr·∫°ng th√°i ƒë·ªÉ theo d√µi vi·ªác x·ª≠ l√Ω duplicate
                handled = False
                            
                if st.button("Check for Duplicates"):
                    # X√°c ƒë·ªãnh v√† hi·ªÉn th·ªã th√¥ng tin v·ªÅ c√°c h√†ng duplicate
                    duplicates = st.session_state.my_df[st.session_state.my_df.duplicated(keep=False)]
                                
                    if duplicates.empty:
                        st.write("No duplicates found.")
                    else:
                        st.write("Duplicates found:")
                        st.write(duplicates)
                        # Hi·ªÉn th·ªã n√∫t ƒë·ªÉ x·ª≠ l√Ω duplicate
                        if st.button("Handle Duplicates"):
                            # X·ª≠ l√Ω duplicate
                            st.session_state.my_df, handled = handle_duplicates(st.session_state.my_df, st.session_state.my_df.columns)
                            
                # Hi·ªÉn th·ªã th√¥ng b√°o khi x·ª≠ l√Ω duplicate th√†nh c√¥ng
                if handled:
                    st.write("Duplicates handled successfully.")
                else:
                    st.write(handled)


            with tab4:
                st.header("Remove Rows with Null")
                
                col1 , col2 = st.columns(2)
                with col1:
                    st.write("Ki·ªÉm tra missing values")
                    st.write(st.session_state.my_df.isnull().sum())

                with col2:
                    selected_columns = st.multiselect("Select columns to remove rows with null values:", st.session_state.my_df.columns, key="RemoveRowsNull")
                            
                    # T·∫°o n√∫t ƒë·ªÉ x√≥a c√°c h√†ng c√≥ gi√° tr·ªã thi·∫øu trong c√°c c·ªôt ƒë∆∞·ª£c ch·ªçn
                    if st.button("Remove Rows with Null"):
                        mask = st.session_state.my_df[selected_columns].notnull().all(axis=1)
                    
                        st.session_state.my_df = st.session_state.my_df[mask]
                        st.success("Removed rows with null values in selected columns.")
                        st.write("Updated missing values:")
                        st.write(st.session_state.my_df.isnull().sum())
            
            with tab5:
                st.header("Change Data Types")
                st.write("Choose column and new data type:")

                # Hi·ªÉn th·ªã danh s√°ch c√°c c·ªôt v√† ki·ªÉu d·ªØ li·ªáu hi·ªán t·∫°i
                st.write("Current data types:")
                st.write(st.session_state.my_df.dtypes)

                selected_column = st.selectbox("Column to convert", st.session_state.my_df.columns, key="convert_column")
                new_dtype = st.selectbox("New data type", ["int32", "int64", "float32", "float64", "object"], key="new_dtype")

                if st.button("Convert"):
                    # √Åp d·ª•ng h√†m convert_column_dtype cho c·ªôt ƒë∆∞·ª£c ch·ªçn
                    st.session_state.my_df = convert_column_dtype(st.session_state.my_df, selected_column, new_dtype)
                    st.write(f"Converted column '{selected_column}' to {new_dtype}")
                    st.write(st.session_state.my_df.dtypes)
                
            with tab6:
                st.header("Check Outliers")
                st.write("Choose column to check outliers")
                
                selected_column = st.selectbox("Column", st.session_state.my_df.columns, key="outlier_select")
                
                if st.button('Check Outliers'):
                    check_outliers_plot(st.session_state.my_df, selected_column)
                    
                    # Hi·ªÉn th·ªã n√∫t ƒë·ªÉ x·ª≠ l√Ω outliers
                    if st.button('Handle Outliers'):
                        st.session_state.my_df = remove_outliers(st.session_state.my_df, selected_column)
                        st.success("Outliers handled successfully.")
            with tab7:
                st.header("Encode Categorical Variables")
                
                # L·ª±a ch·ªçn ph∆∞∆°ng ph√°p m√£ h√≥a t·ª´ ng∆∞·ªùi d√πng
                encode_method = st.selectbox("Select encoding method:", ["One-Hot Encoding", "Ordinal Encoding", "Label Encoding"])

                # M√£ h√≥a d·ªØ li·ªáu theo ph∆∞∆°ng ph√°p ƒë∆∞·ª£c ch·ªçn
                if encode_method == "One-Hot Encoding":
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = one_hot_encode(st.session_state.my_df, column)
                elif encode_method == "Ordinal Encoding":
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = ordinal_encode(st.session_state.my_df, column)
                else:  # Label Encoding
                    column = st.selectbox("Select column to encode:", st.session_state.my_df.columns)
                    df_encoded = label_encode(st.session_state.my_df, column)

                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.write("Encoded DataFrame:")
                st.write(df_encoded)

            with tab8:
                st.header("Save dataset")
    
                # Ki·ªÉm tra n·∫øu c√≥ DataFrame v√† ƒë√£ clean data
                if 'my_df' in st.session_state and st.session_state.my_df is not None:
                    st.write("Your cleaned dataset:")
                    st.write(st.session_state.my_df.head())
                    
                    # X√°c ƒë·ªãnh t√™n file m·∫∑c ƒë·ªãnh
                    default_filename = None
                    if uploaded_files:
                        # N·∫øu c√≥ file t·∫£i l√™n, s·ª≠ d·ª•ng t√™n file ƒë·∫ßu ti√™n k√®m theo "_cleaned.csv"
                        default_filename = uploaded_files[0].name.split('.')[0] + "_cleaned.csv"
                    filename = st.text_input("Enter a filename to save as:", default_filename)
                    # Th√™m n√∫t ƒë·ªÉ l∆∞u dataset
                    if st.button("Save Cleaned Dataset"):
                        
                        if filename.strip() == "":
                            st.warning("Please enter a valid filename.")
                        else:
                            save_dataset(st.session_state.my_df, filename)
                            
                            # Hi·ªÉn th·ªã link ƒë·ªÉ t·∫£i file v·ªÅ
                            download_link = get_download_link(st.session_state.my_df, filename, "Click here to download the cleaned dataset")
                            st.markdown(download_link, unsafe_allow_html=True)
                else:
                    st.warning("No cleaned dataset available. Please clean your data first.")
            
            
            
            
            
            
            

        
    


    



    
    

    